INTRODUCTION

The brain is a highly complex, nonlinear, and parallel computer (information-processing system). It has the capability to organize its structural constituents, known as neurons, so as to perfrom certain computations many times faster than the fastest digital computer in existence today

At birth, a brain has great structure and the ability to build up its own rules through what we usually refer to as experience. Indeed, experience is built up over time, with the most dramatic development (i.e. hard-wiring) of the human brain taking place during the first two years from birth; but the development continues well beyond that stage

A developing neuron is synonymous with a plastic brain: plasticity permits the developing nervous system to adapt to its surrounding environment.

A neural network is a machine that is designed to model the way in which the brain performs a particular task or function of interest; the network is usually implemented by using electronic components or is simultaed in software on digital computer.

To achieve good performance, neural networks employ a massive interconnection of simple computing cells referred to as neurons or processing units.

A neural network is a massively parallel distributed processor made up of simple processing units, which has a natural propensity for storing experiental knowledge and making it available for use. It resembles the brain in two respects:
1. Knowldege is acquired by the network from its environment through a learning process.
2. Interneuron connection strengths, known as synaptic weights, are used to store the acquired knowledge.

The procedure used to perform the learning process is called a learning algorithm, the function of which is to modify the synaptic weights of the network in an orderly fashion to attain a desired design objective.

However, it is also possible for a neural network to modify its own topology, which is motivated by the fact that neurons in the human brain can die and that new synaptic connections can grow.

A neural network derives its computing power through, first, its massively parallel distributed structure and, second, its ability to learn and therefore generalize. Generalization refers to the neural network producing reasonable outputs for inpts not encountered during training (learning). These two information-processing capabilities make it possible for neural networks to solve complex (large-scale) problems that are currently intractable.

It is important to recognize, however, that we have a long way to go before we can build a computer architecture that mimics a human brain. (Reference to Blue Brain Project?)

The use of neural networks offers the following useful properties and capabilities:
1. Nonlinearity: the nonlinearity is of a special kind in the sense that it is distributed throughout the network
2. Input-output mapping: see explanation of supervised learning and analogy between the input-output mapping performed by a neural network and nonparametric statistical inference
3. Adaptivity: neural networks have a built-in capability to adapt their synaptic weights to changes in the surrounding environment. In particular, a neural network trianed to operate in a specific environment can be easily retrained to deal with minor changes in the operating environmental conditions. --> stability-plasticity dilemma
4. Evidential response --> not important
5. Contextual information: knowledge is represented by the very structure and activation state of a neural network
6. Fault tolerance: a neural network, implemented in hardware form, has the potential to be inherently fault tolerant, or capable fo robust computation, in the sense that its performance degrades gracefully under adverse operating conditions. For example, if a neuron or its connecting links are damaged, recall of a stored pattern is impaired in quality. However, due to the distributed nature of information stored in the network, the damage has to be extensive before the overall response of the network is degraded seriously. Thus, in principle, a neural network exhibits a graceful degradation in performance rather than catastrophic failure.

The design of a neural network is motivated by analogy with the brain, which is a living proof that fault tolerant parallel processing is not only physically possible but also fast and powerful.

HUMAN BRAIN

The receptots convert stimuli from the human body or the external environment into electrical impulses that convey information to the neural net. The effectors convert electrical impulses generated by the neural net into discernible responses as system outputs.

The brain maeks up for the relatively slow rate of operation of a neuron by having a truly staggering number of neurons (nerve cells) with massive interconnections between them. It is estimated that there are approximately 10 billion neurons in the human cortex, and 60 trilion synapses or connections.

In traditional descriptions of neural organization, it is assumed that a synapse is a simple connection that can impose excitation or inhibition, but not both on the receptive neuron.

In an adult brain, plasticity may be accounted for by two mechanisms: the creation of new synaptic connections between neurons, and the modification of existing synapses.

Neurons come in a wide variety of shapes and sizes in different parts of the brain.

The artificial neurons we use to build our neural networks are truly primitive in comparison to those found in the brain. The neural networks we are presently able to design are just as primitive compared to the local circuits and the interregional circuits in the brain. What is really satisfying, however, is the remarkable progress that we have made on so many fronts during the past two decades. With neurobiological analogy as the source of inspiration, and the wealth of theoretical and technological tools that we are bringing together, it is certain that in another decade our understanding of artificial neural networks will be much more sophisticated than it is today.

MODELS OF A NEURON

A neuron is an information-processing unit that is fundamental to the operation of a neural network. The model of a neuron forms the basis for designing (artificial) neural networks. We identify three basis elements of the neuronal model:
1. A set of synapses or connecting links, each of which is characterized by a weights or strength of its own.
2. An adder for summing the input signals, weighted by the respective synapses of the neuron; the operations described here constitue a linear combiner.
3. An activation function for limiting the amplitude of the output of a neuron. The activation function is alos referred to as a squashing function in that it squashes (limits) the permissible amplitude range of the output signal to some finite value.

Notation: linear combiner denoted by u, net input denoted by v, output by y, bias by b
net input also referred to as induced local field or activation potential

TYPES OF ACTIVATION FUNCTION

Neuron with threshold function as activation function: McCulloch-Pitts model, in recognition of the pioneering work done by McCulloch and Pitts. All-or-none property of the McCulloch-Pitts model.

The sigmoid function, whose graph is s-shaped, is by far the most common form of activation function used in the construction of artificial neural networks. It is defined as a strictly increasing function that exhibits a graceful balance between linear and nonlinear behavious.

For the logistic function: as the slope parameter approaches infinity, the sigmoid function becomes simply a threshold function. Whereas a threshold function assumes the value of 0 or 1, a sigmoid function assumes a continuous range of values from 0 to 1. Note also that the sigmoid function is differentiabl, whereas the threshold function is not.

Allowing an activation function of the sigmoid type to assume negative values has analytical benefits --> see Chapter 4

NEURAL NETWORKS VIEWED AS DIRECTED GRAPHS

A signal-flow graph is a network of directed links (branches) that are interconnected at certain points called nodes. A typical node j has an associated node signal x_j. A typical directed link originates at node j and terminates on node k; it has an associated transfer function or transmittance that specifies the manner in which the signal y_k at node k depends on the signal x_j at node j.

Mathematical definition of a neural network:
A neural network is a driected graph consisting of nodes with interconnecting synaptic and activation links, and is characterized by four properties:
1. Each neuron is represented by a set of linear synaptic links, an externally applied bias, and a possibly nonlinear activation link. The bias is represented by a synaptic link connected to an input fixed at +1.
2. The synaptic links of a neuron weights their respective input signals.
3. The weighted sum of the input signals defines the induced local field of the neuron in question.
4. The activation link squashes the induced local field of the neuron to produce an output.

NETWORK ARCHITECTURES

The manner in which the neurons of a neural network are structured is intimately linked with the learning algorithm used to train the network. We may therefore speak of learning algorithms (rules) used in the design of neural networks as being structured.

In general, we may identify three fundamentally different classes of network architectures: single-layer feedforward networks, multilayer feedforward networks, recurrent networks.

SINGLE-LAYER FEEDFORWARD NETWORKS

In a layered neural network the neurons are organized in the form of layers.

Such a network is called a single-layer network, with the designation "single-layer" referring to the output layer of computation nodes (neurons). We do not count the input layer of source nodes because no computation is performed there.

MULTILAYER FEEDFORWARD NETWORKS

The source nodes in the input layer of the network supply resepcetive elements of the activation pattern (input vector), which constitute the input signals applied to the neurons (computation nodes) in the second layer (i.e. the first hidden layer). The output signals of the second layer are used as inpits to the third layer, and so on for the rest of the network. Typically the neurons in each layer of the network have as their inputs the output signals of the preceding layer only. The set of output signals of the neurons in the output (final) layer of the network constitutes the overall response of the network to the activation patterbs supplied by the source nodes in the input (first) layer.

KNOWLEDGE REPRESENTATION

Definition of knowledge by Fischler and Firschein:
Knowledge refers to stored information or models used by a person or machine to interpret, predict, and appropriately respond to the outside world.

In real-world applications of intelligent machines, it can be said that a good solution depends on a good representation of knowledge.

The possible forms of representation from the inputs to internal network parametres are highly diverse, which tends to make the development of a satisfactory solution by means of a neural network a real design challenge.

A major task for a neural network is to learn a model of the world (environment) in which it is embedded and to mantain the model sufficiently consistent with the real world so as to achieve the specified goal of the application of interest.

The observations [of the world] provide the pool of information from which the examples used to train the neural network are drawn.

The examples can be labeled or unlabeled. In labeled examples, each example representing an input signal is paired with a corresponding desired response (i.e. target output). On the other hand, unlabeld examples consist of different realizations of the input signal by itself. In any event, a set of examples, labeled or otherwise, represents knowledge about the environment of interest that a neural network can learn through training.

A set of input-output pairs, with each pair consisting of an input signal and the corresponding desired response, is referred to as a set of training data or training sample.

Design of a neural network consists of two steps: learning and generalization.
- First, an appropriate architecture is selected for the neural network. [...] A subset of examples is then used to train the network by means of a suitable algorithm.
- The recognition performance of the trained network is tested with data not seen before. [...] Generalization is a term borrowed from psychology.

The design of a neural network is based directly on real-life data, with the data set being permitted to speak for itself --> No model of the outside world is required.

In a neural network of specified architecture, knowledge representation of the surrounding environment is defined by the values taken on by the free parameters (i.e. synaptic weights and biases) of the network. The form of this knowledge representation constitutes the very design of the neurla network, and therefore holds the key to its performance.

--------------------------------------------------------------------------------------

LEARNING PROCESS

The property that is of primary significance for a neural network is the ability of the network to learn from its environment, and to improve its performance through learning. The improvement in performance takes place over time in accordance with some prescribed measure. A neural network learns about its environment through an interactive process of adjustments applied to its synaptic weights and bias levels. Ideally, the network becomes more knowledgeable about its environment after each iteration fo the learning process.

Definition of learning, adapted from Mendel and McClaren:
Learning is a process by which the free parameters of a neural network are adapted through a process of stimulation by the environment in which the network is embedded. The type of learning is determined by the manner in which the parameter changes take place.

Then, the definition implies the following sequence of events:
1. The n.n. is stimulated by an environment
2. The n.n. undergoes changes in its free parameters as a result of this stimulation
3. The n.n. responds in a new way to the environment because of the changes that have occurred in its internal structure.

A prescribed set of well-defined rules for the solution of a learning problem is called a learning algorithm. 
Learning algorithms differ from each other in the way in which the adjustment to a synaptic weight of a neuron is formulated. Another factor to be considered is the manner in which a neural network relates to its environment. In this latter context we speak of a learning paradigm that refers to a model of the environment in which the neural network operates.

Hebbian learning is inspired by neurobiological considerations.

HEBBIAN LEARNING

Hebb's postulate of learning is the oldest and most famous of all learning rules; it is named in honor of the neuropsychologist Hebb.

Two-part rule:
1. If two neurons on either side of a synapse (connection) are activated simultaneously (i.e. synchronously) then the strength of that synapse is selectively increased.
2. If two neurons on either side of a synapse are activated asynchronously, then that synapse is selectively weakened or eliminated.

Such a synapse is called Hebbian synapse (although original Hebb rule did not contain part 2). More precisely, we define a Hebbian synapse as a synapse that uses a time-dependent, highly local, and strongly interactive mechanism to increase synaptic efficiency as a function of the correlation between the presynaptic and postsynaptic activities.

Four key mechanisms that characterize an Hebbian synapse:
1. Time-dependent mechanism: modifications depend on the exact time of occurrence of the presynaptic and postsynaptic signals.
2. Local mechanism: local synaptic modification that is input specific
3. Interactive mechanism: the occurrence of a change in a Hebbian synapse depends on signal on both sides of the synapse. 
4. Conjectional or correlation mechanism. One interpretation of Hebb's postulate of learning is that the conditions for a change in synaptic efficiency is the conjuction of presynaptic and postsynaptic signals. Thus, according to this interpretation, the co-occurrence of presynaptic and postsynaptic signals (within a short interval of time) is sufficient to produce the synaptic modification. [...] Accordingly, a Hebbian synapse is also referred to as a correlation synapse. Correlation is indeed the basis of learning. 

We may generalize the concept of a Hebbian modification by recognizing that positively correlated activity produces synaptic strengthening, and that either uncorrelated or negatively correlated activity produces synaptic weakening.

LEARNING WITH A TEACHER

We now turn our attention to learning paradigms. We begin by considering learing with a teacher, which is also referref to as supervised learning.

We may think of the teacher as having knowledge of the environment, with that knowledge being represented by a set of input-output examples. The environment is, however, unknown to the neural network.

Suppose now that the teacher and the nerual network are both exposed to a training vector (i.e. example) drawn from the environment. By virtue of built-in knowledge, the teacher is able to provide the neural network with a desired response for the training vector. Indeed, the desired response represents the optimum action to be performed by the neural network. The network parameters are adjusted under the combined influence of the training vector and the error signal. The error signal is defined as the difference between the desired response and the actual response ot the network. This adjustment is carried out iteratively in a step-by-step fashion with the aim of eventually making the neural network emulate the teacher. in this way knowledge of the environment available to the teacher is transferred to the neural network through training as fully as possible. When this condition is reached, we may then dispense with the teacher and let the neural network deal with the environment completely by itself.

As a performance measure for the system we may think in terms of the mean-square error or the sum of squared errors over the training sample, defined as a function of the free parameters of the system. This function may be visualized as a multidimensional error-performance surface or simply error surface, with the free parameters as coordinates.

Any given operation of the system under the teacher's supervision is represented as a point on the error surface. For the system to improve performance over time and therefore learn from the teacher, the operating point has to move down successively toward a minimum point of the error surface; the minimum point may be a local minimum or a global minimum. A supervised learning system is able to do thsi with the useful information it has about the gradient of the error surface corresponding to the current behaviour of the system.

Given an algorithm designed to minimize the cost function, an adequate set of input-output examples, and enough time permitted to do the training, a supervised learning system is usually able to perform such tasks as pattern classification and function approximation.

LEARNING WITHOUT A TEACHER

In supervised learning, the learning process takes place under the tutelage of a teacher. However, in the paradigm known as learning without a teacher, there is no teacher to oversee th learning process. That is to say, there are no labeled examples of the function to be learned by the network.

Two subdivisions: reinforcement learning and unsupervised learning

REINFORCEMENT LEARNING

In reinforcement learning, the learning of an input-output mapping is performed through continued interaction with the environment in order to minimize a scalar index of performance.

UNSUPERVISED LEARNING

In unsupervised or self-organized learning there is no external teacher or critic to oversee the learning process. Rather, provision is made for a task-independent measure of the quality of representation that the network is required to learn, and the free parameters of the network are optimized with respect to that measure.

LEARNING TASKS

The choice of a particular learning algorithm is influence by the learning task that a neural network is required to perform.

FUNCTION APPROXIMATION

Consider a nonlinear input-output mapping described by the functional relationship d = f(x), where the vector x is the input and the vector d the output. The vector-valued function f is assumed to be unknown. To make up for the lack of knowledge about the function f, we are given the set of labeled examples (x_i,d_i). The requirement is to design a neural network that approximates the unknown function f such that the function F describing the input-output mapping actually realized by the network is close enough to f in an Euclidean sense over all inputs, i.e. ||F(x) - f(x)|| < eps for all x.
Provided that the size of the training set is large enough and the network is equipped with an adequate number of free parameters, then the approximation error eps can be made small enough for the task.
The approximation problem described here is a perfect candidate for supervised learning with x_i playing the role of input vector and d_i serving the role of desired response.
--> suoervised learning as an approximation problem
